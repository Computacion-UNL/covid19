# Modelo para el diagn√≥stico de Covid-19 Mediante el An√°lisis de Radiograf√≠as Pulmonares empleando Redes Neuronales Convolucionales (CNN)‚Äù

Modelo basado en la Arquitectura VGG-16 que emplea redes neuronales convolucionales para el diagn√≥stico de Covid-19 a 
partir del an√°lisis de radiograf√≠as pulmonares 

## Comenzando üöÄ

Estas instrucciones son el complemento al Trabajo de Titulaci√≥n, denominado ‚ÄúDiagn√≥stico de Covid-19 Mediante el An√°lisis 
de Radiograf√≠as Pulmonares Empleando un Modelo Basado en Redes Neuronales Convolucionales (CNN)‚Äù, el cual hace referencia 
a este repositorio. Estas instrucciones y su descripci√≥n, son el resultado de un largo proceso de desarrollo por lo que
solo se ha descrito las partes m√°s relevantes del mismo, de tal forma que permitan al usuario/stakeholder, obtener una 
mejor perspectiva de lo que se hizo durante el transcurso del presente TT. 
Este es el primero de dos repositorios, los cuales completan la funcionalidad del sistema. En este primer repositorio
contiene el backend del modelo (c√≥digo y API), adem√°s de los archivos utilizados en Jupyter pare el entrenamiento y 
creaci√≥n de cada uno de los modelos que fueron entrenados acorde a la carga establecida, lo mismo que se encuentran en 
la carpeta Models de este mismo repositorio, as√≠ como el script que hace uso de los modelos entrenados y script 
concerniente a la creaci√≥n de la API.

Mira **Deployment** para conocer como desplegar el proyecto.


### Pre-requisitos üìã
Estas instrucciones est√°n orientadas al desarrollo del modelo en un ambiente local usando tanto **JupyterLab** y **PyCharm** 
como IDE's de desarrollo, por lo que se recomienda cumplir con los requisitos que m√°s adelante se describen para evitar 
problemas de rendimiento. Estos requisitos se deben considerar en caso de implementar el modelo en un ambiente de 
desarrollo local (como lo es en este caso), si el modelo en cuesti√≥n se desea implementar ambiente orientado a la 
computaci√≥n en la nube como Azure o Google Colab, se recomienda leer la documentaci√≥n de este tipo de servicios, pues 
suelen disponer de ciertas librer√≠as y recursos que pueden ser utilizados sin necesidad de instalarlos.

### Componentes de Hardware utilizados
* Inter (R) Core(TM) i7-10750H
* Nvidia GeForce 2070 Super con 8 GB de NVRAM
* 32 GB de RAM
* Windows 10 Enterprise de 64-bits
### Preparaci√≥n del ED
Como entorno de desarrollo (ED) se opt√≥ por usar JupyterLab y PyCharm, del modelo se usar√° Python y su gestor de paquetes
pip. Adem√°s, se usar√° la suit de Anaconda, para la creaci√≥n y gesti√≥n de entornos virtuales de desarrollo, la gesti√≥n de
paquetes con su gestor llamado conda.
####Python
Como lenguaje de programaci√≥n se usar√° python en su versi√≥n 3.8.8 y pip 21.0.0, ya que son versiones compatibles con las
librer√≠as las que se utilizar√°n en el desarrollo del modelo, tales como Tensorflow, Scikit-learn y Keras. 
Para una mejor referencia de las versiones son compatibles con las librer√≠as a utilizar, visite 
[IArtificial.net](https://www.iartificial.net/librerias-de-python-para-machine-learning/), y verifique las versiones y 
su compatibilidad. Una vez determinadas las versiones y su compatibilidad con Python, procedemos a su instalaci√≥n, para 
lo cual seguimos los siguientes pasos:
* Antes de empezar, debemos comprobar si tenemos instalado alguna version de Python, para ello utilizamos el siguiente
comando:
  ```
  python --version
  ```
* Verificar la version de **pip** utilizamos:
  ```
  pip --version
  ```
* En caso de que las versiones sean inferiores o incompatibles (dependiendo del an√°lisis realizado anteriormente) con 
ciertas librer√≠as, debe actualizar las versiones tanto de Python como de pip, en Windows se debe descargar la versi√≥n 
requerida de Python desde la [p√°gina Oficial de descarga de Python ](https://www.python.org/downloads/).
Una vez all√≠, deber√° seleccionar una de las versiones disponibles y descargarla (en nuestro caso la versi√≥n 3.8). 
Luego de haberla descargado, procesa a ejecutar el instalador. En caso de que exista una versi√≥n de Python instalada en 
su PC, la opci√≥n **Actualizar ahora** aparecer√° y deber√° seguir las instrucciones que el Wizard de instalaci√≥n muestre 
en pantalla. En caso de que la versi√≥n 2.xy o 3.xy ya est√° instalada y exista una actualizaci√≥n a la versi√≥n 2.xz o 3.xz,
la versi√≥n existente de Python ser√° reemplazada por la versi√≥n reci√©n instalada. 
Por √∫ltimo, si la versi√≥n instalada de Python es 2.x o 3.x, y se descarga el archivo de instalaci√≥n de alguna versi√≥n
posterior como 2.y o 3.y, la versi√≥n m√°s reciente se instalar√° como una versi√≥n por separado y la versi√≥n anterior no ser√°
reemplazada ni eliminada. Por lo que al finalizar el proceso instalaci√≥n, es posible que disponga de m√°s de una versi√≥n 
de python, en este caso es necesario especificar una versi√≥n es espec√≠fico que desee ha utilizar, podr√° usar el siguiente 
comando en el cmd del sistema o Windows PowerShell:

  * Para usar alguna versi√≥n instalada espec√≠fica de Python 2:
    ```
    py -2.xy
    ```
  * Para usar alguna versi√≥n instalada espec√≠fica de Python 3:
    ```
    py -3.xy
    ```
* En cuanto a las versiones de pip, desde Python 3.4 en adelante viene incluido por defecto dentro de los instaladores 
binarios del lenguaje, no obstante si desea actualizar dicha versi√≥n puede utilizar el siguiente comando:
     ```buildoutcfg
    c:\ruta\a\python3 -m pip install --upgrade pip
    ```
####Anaconda
Anaconda, es una Suite de c√≥digo abierto, que contiene una serie de aplicaciones, librer√≠as y herramientas dise√±adas para 
el desarrollo orientado a la Inteligencia Artificial y a la Ciencia de datos con Python, es por esta raz√≥n, que dispone 
la creaci√≥n de entornos virtuales y de IDE's como Jupyter, para el desarrollo y visualizaci√≥n de resultados m√°s puntuales.
El tipo de desarrollo que se puede llevar a cabo, puede ser tanto con servicios en la nube, como entornos de desarrollo 
local, con lo cual usar√° los recursos de la m√°quina local (CPU, GPU y RAM), adem√°s con su gestor de paquetes **conda**, 
nos ha permitido la instalaci√≥n de diferentes versiones de librer√≠as, las cuales al estar aisladas en entornos 
virtuales, posibilitan el ajuste fino de los hiperpar√°metros de forma escalable y controlable, a la vez, nos ofrece una
mayor tolerancia a fallos y una identificaci√≥n y correcci√≥n de errores m√°s r√°pida y precisa:

Para instalar Anaconda, sigua los siguientes pasos:
* Descargar el instalador de [Anaconda](https://www.anaconda.com/products/individual#windows)
* Ejecute el instalador, acepte los t√©rminos y condiciones
* Seleccione la instalaci√≥n ¬®Solo yo¬® a menos que otros usuarios requieran del software.
* Selecciones la carpeta de destino, en nuestro caso, seleccionamos la siguiente ruta ``C:\Users\user\anaconda3``, para m√°s 
informaci√≥n revise las [preguntas frecuentes](https://docs.anaconda.com/anaconda/user-guide/faq/#distribution-faq-windows-folder)
* Elija si desea agregar **Anaconda** a su variable de entorno PATH. 
* Elija si desea registrar Anaconda como su Python predeterminado.
* Verifique los paquetes a instalar, conforme a la [documentaci√≥n](https://docs.anaconda.com/anaconda/install/windows/),
si todos los pasos se cumplieron sin inconvenientes y ha considerado los aspectos resaltados anteriormente, 
selecciones **instalar**.
* En las versiones recientes de Anaconda, de forma opcional, se puede instalar PyCharm, en nuestro caso PyCharm se utiliz√≥ para la construcci√≥n del modelo debido a los pluggins que son de mucha 
ayuda al momento de desarrollar con Python.
* Para finalizar, compruebe que anaconda se ha instalado correctamente en su PC, para lo cual desde cmd o desde la 
Anaconda Powershell Prompt, utilice el siguiente comando:
  ```buildoutcfg
  >conda -- version 
  conda 4.10.3 
  ```
Una vez instalado la suit de Anaconda3 y luego de haber verificado que funciona correctamente, vamos a crear el ambiente 
de trabajo o environment (env) sobre el cual instalaremos las diferentes librer√≠as y dependencias necesarias para el 
modelo. Para crear un nuevo env, utilizamos el siguiente comando:
```buildoutcfg
conda create --name myenv
# Sentencia simplificada
conda create -n myenv
```
_Da la sentecia anterior se remplaza ``myenv`` por el nombre que identifique a su entorno._

**Nota**: **conda**, instalar√° todas las dependencias en el entorno ``base`` que se inicializa por defecto. 
Se recomienda usar un entorno de desarrollo independiente para este modelo, de tal forma que no afecte a los 
dem√°s proyectos locales o el modelo a desarrollar se vea afectado.

### Instalaci√≥n librer√≠asüîß
####Cuda Toolkit
En esta secci√≥n se explica de forma detallada como instalar TensorFlow con compatibilidad con CUDA, cuDNN y GPU en
Windows 10, de tal forma que la GPU disponible en el sistema pueda ser incorporada a las tareas de procesamiento que 
requieran alto rendimiento, sobre todo en im√°genes (las im√°genes ser√°n la base para entrenar y probar el modelo) que es 
donde las GPU's se especializan, debido a su procesamiento en paralelo vs. procesamiento de serie de la CPU. Los pasos 
que se muestran a continuaci√≥n, se implementaron de acuerdo a la gu√≠a de 
[Nvidia Developer](https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html), en la que se 
resalta los siguientes requisitos previos a la instalaci√≥n de TF y de NVIDIA CUDA Toolkit:
* Microsoft Visual Studio
* NVIDIA CUDA Toolkit
* NVIDIA cuDNN
* Tensorflow (with GPU support)
####Microsoft Visual Studio 
Como primer requisito tenemos que descargar e instalar una versi√≥n compatible de Microsoft Visual Studio, ya que CUDA
utiliza ciertos compiladores de Visual Studio como Versi√≥n de MSVC 191x y Versi√≥n de MSVC 192x, sin estos compiladores
previamente instalados, al momento de instalar CUDA nos enviar√° un error, el cual reportar√°
la falta de dichos componentes.
Al momento de redactar el presente TT, se ha instalado una de las versiones m√°s recientes 
de Visual Studio Community 2019 (VS) v. 16.10.3, para lo cual realizamos los siguientes pasos:
* Descargar el instalador de Visual Studio, en nuestro caso elegimos la version [Community 2019](https://visualstudio.microsoft.com/), 
por ser una plataforma para el desarrollo con pol√≠ticas de c√≥digo abierto, en caso de optar una version diferente
consulte la [documentaci√≥n](https://docs.anaconda.com/anaconda/install/windows/).
* Una vez descargado el instalador, procedemos a instalar VS siguiendo las instrucciones del wizard de instalaci√≥n.
* Durante el proceso de instalaci√≥n, aparecer√° un mensaje, que indica si desea o no usar cargas de trabajo, en nuestro 
caso obviamos dicha carga seleccionando la opci√≥n continuar.
* Al finalizar la instalaci√≥n reinicio el PC, ya que si intenta instalar CUDA Toolkit es posible que se produzca un
error provocado por la ejecuci√≥n de VS.
####NVIDIA CUDA Toolkit
La versi√≥n de CUDA instalada para el desarrollo del presente modelo es la 11.4, la cual es compatible con la GPU Nvidia 
RTX 2070 S√∫per que disponemos, por lo que, a continuaci√≥n se detalla el proceso de instalaci√≥n:

* Primero es necesario elegir la versi√≥n de CUDA compatible para la version de TF y la GPU, para ello, verifique los 
requerimientos en la p√°gina de [TF](https://www.tensorflow.org/install/gpu), de la cual hemos consideramos lo siguiente:
  * NVIDIA¬Æ GPU drivers ‚ÄîCUDA¬Æ 11.2 requires 450.80.02 o superiores.
  * CUDA¬Æ Toolkit ‚ÄîTensorFlow supports CUDA¬Æ 11.2 (TensorFlow >= 2.5.0)
  * cuDNN SDK 8.1.0 cuDNN versions.
* Por lo tanto, la versi√≥n m√≠nima de CUDA es a 11.2 (en nuestro caso elegimos la opci√≥n 11.4), la cual se encuentra en la 
p√°gina oficial de descarga de [Nvidia](https://www.nvidia.com/download/index.aspx?lang=en-us), en el apartado de Nvidia
Driver Downloads, introducimos los par√°metros de nuestra tarjeta gr√°fica, los cuales se aprecian en la figura adjunta.

    **Nota:** los par√°metros var√≠an significativamente entre el tipo de PC que utilice y la gr√°fica que disponga.
    ![img1](Capturas/ParametrosCUDA.PNG)
* Ejecutamos el instalador y seguimos las instrucciones del Wizard. Al finalizar, habremos instalado los drivers para la 
tarjeta gr√°fica los cuales se pueden verificar en el software GeForce Experience.
* Seguidamente, seleccionamos la version de [CUDA](https://developer.nvidia.com/cuda-toolkit-archive) disponible, en 
nuestro, seg√∫n la documentaci√≥n de TF, podemos instalar una versi√≥n igual o superior a la 11.2, por lo que instalaremos 
la versi√≥n m√°s actual hasta la fecha de hacer redactado este TT, la versi√≥n 11.4, para Windows 10 (tal como se 
muestra en la imagen adjunta)
![img2](Capturas/SelectTargetPlatform.PNG)
* Una vez haya finalizado la descarga, obtendremos un archivo .zip el cual se debe descomprimir para obtener el instalador
de CUDA e iniciar la instalaci√≥n de NVIDIA CUDA.
* Dentro del Wizard de instalaci√≥n, se debe elegir la ruta de instalaci√≥n, en nuestro caso, la ruta ser√° la que est√°
definida por defecto.
* Al inicializarse el instalador, se muestra una interfaz como se muestra en la figura adjunta, en ella deber√° seleccionar 
el tipo de instalaci√≥n Express (r√°pida) o Custom (perzonalizada). En nuestro caso elegimos la opci√≥n de instalaci√≥n r√°pida  
![TipoInstalacion.PMG](Capturas/TipoInstalacion.PNG)
* En el siguiente apartado, es posible elegir la ruta de instalaci√≥n de los diferentes componentes de CUDA, en nuestro 
caso ``C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.0`` 
* En este paso, se evidencian las dependencias de Visual Studio, aunque no requiere de nuestra intervenci√≥n,
ya que simplemente debemos marcar siguiente, no obstante se puede corroborar que VS forma parte del funcionamiento de 
CUDA, raz√≥n por la quno e es posible instalar CUDA sin previamente instalar una version compatible de VS.
![DependenciasVS.PNG](Capturas/DependenciasVS.PNG)
  * Por √∫ltimo, se despliega la ventana de instalaci√≥n final, en donde se muestran todas las dependencias y librer√≠as que 
  se instalar√°n, adem√°s, en la parte izquierda de la ventana (se muestra en la figura adjunta), se puede comprobar que la 
  palabra **final** est√° resaltada, lo cual indica que las configuraciones establecidas han sido instaladas.
  ![FinalCap.PNG](Capturas/FinalCap.PNG)
* Para comprobar la versi√≥n de CUDA instalada, puede utilizar el siguiente comando:
```buildoutcfg
nvidia-smi
```
####Nvidia cuDNN
 En cuanto a la versi√≥n de esta librer√≠a, [TF](https://www.tensorflow.org/install/gpu) recomienda utilizar la version 
 SDK 8.1.0, esta librer√≠a, nos permitir√° acelerar la CNN proporcionando implementaciones altamente ajustadas para las 
 rutinas de convoluci√≥n hacia adelante y hacia atr√°s, asi como las fases de agrupaci√≥n, normalizaci√≥n y capas de activaci√≥n.
Los pasos que seguimos para instalar esta librer√≠a se describen a continuaci√≥n:
 * En primer lugar debe descargar el instalador de la librer√≠a, para lo cual es necesario registrarse en Nvidia Development y
disponer de una cuenta.
 * Al ingresar a la p√°gina de descarga con su cuenta, acepte los t√©rminos y condiciones de la comunidad y elija la 
versi√≥n compatible, en cuDNN v8.2.2 (July 6th, 2021) para CUDA 11.4 en Windows 10.
 * Como siguiente se procede a descomprimir los archivos descargados en cnDNN, los cuales se copiaran a una ruta en al
cual se ha instalado la CUDA, en nuestro caso, los archivos se copiaron en la siguiente ruta:
``C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.0``
 * Por √∫ltimo, agregamos CUDA a las variables de entorno del sistema. Las variables de entorno que a√±adimos son:
   * ``C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.0\bin``
   * ``C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.0\libnvvp``
####Tensorflow con soporte de GPU
 Para este apartado, es muy importante haber instalado correctamente CUDA, cuDNN y adem√°s, haber agregado correctamente 
 las variables de entorno, caso contrario, la GPU no podr√° ser reconocida al momento de importar la librer√≠a a un
 determinado proyecto. Asumiendo que las configuraciones anteriores se han realizado correctamente, procedemos a instalar
 la librer√≠a de TF. Para ello seguimos los siguientes pasos:

 * Mediante el Powershell Prompt de conda o s√≠mbolo del sistema de Windows (si agreg√≥ conda a las variables de entorno), 
crear un entorno virtual (Env), en el cual se instalar√°n todas las librer√≠as y dependencias incluyendo tensorflow.
Utilice el siguiente comando, especificando el nombre (puede usar cualquier otro) y la versi√≥n de python, en caso de que
tenga instalada m√°s de una versi√≥n:
    ```buildoutcfg
    conda create --name tensorflow python=3.8
    ```
 * Compruebe si el entorno fue creado, usando ``conda env list``. Este comando listar√° todos los entornos creados y
gestionados por conda, verifique si ``tensorflow``se encuentra en la lista
![EnvList.PNG](Capturas/EnvList.PNG)
 * Una vez comprobado que el entorno se ha creado exitosamente, activamos dicho entorno usando el comando ``conda activate``
seguido del nombre del entorno, en nuestro caso ``tensorflow``
    ```buildoutcfg
    conda activate tensorflow
    ```
    ![ActivacionEntorno.PNG](Capturas/ActivacionEntornos.PNG)   

   N√≥tese, que el nombre que antecede a la ruta de Powershell previo a la ejecuci√≥n del comando lo antecede la palabra 
``base`` que es el entorno por defecto que activa conda. Este nombre se remplaza por el nombre del entorno que se acaba 
de activar con el comando anterior, en nuestro caso ``tensorflow``
 * Por √∫ltimo instalamos TensorFlow con soporte GPU, para lo cual usamos el siguiente comando, especificando el n√∫mero 
de versi√≥n:
    ```buildoutcfg
    pip install tensorflow-gpu==2.4.0
    ```
 * Tras finalizar el proceso de instalaci√≥n, con el siguiente comando, procedemos a comprobar la instalaci√≥n de TensorFlow 
y verificar si la GPU esta habilitada y disponible para su uso. Usando el siguiente comando en la consola, comprobamos 
la disponibilidad de la GPU:
    ```buildoutcfg
    % python
    >>> import tensorflow as tf
    >>> tf.test.is_gpu_available()
    ```
    ![CheckTF.PNG](Capturas/CheckTF.PNG)
    Como se puede apreciar al la imagen adjunta, en la l√≠nea final ``True`` indica que la GPU esta habilitada para su uso. 
Como datos adicionales, tenemos el nombre de la GPU, el tipo de dispositivo y dem√°s caracter√≠sticas referentes a la 
tarjeta gr√°fica.

#### Instalaci√≥n de librer√≠as adicionales
Para instalar el resto de librer√≠as adicionales como open cv, keras, scikit-learn, jupyterlab, las cuales son necesarias 
para la ejecuci√≥n del modelo usar, el siguiente comando:
```buildoutcfg
pip install -r requirements.txt
```

## Entrenamiento del modelo ‚öôÔ∏è

Para entrenar el modelo, se us√≥ el IDE de PyCharm y JupyterLab como entornos de desarrollo.
Si utiliza JupiterLab bastar√° con activar el entorno, tal como se hizo en los pasos anteriores. 
En caso de usar PyCharm, debera abrir el proyecto desde el IDE y configurar el int√©rprete (en la mayor√≠a de los casos). Para ello, siga los siguientes pasos:
* Dir√≠jase a la pesta√±a ubicada en la parte inferior derecha, donde se aprecia el nombre int√©rprete, en nuestro caso
``Python3.9``. 
![PyCharmInterprete1.png](Capturas/PyCharmInterprete1.png)
* Seleccione la opci√≥n de **Add interpreter** o **a√±adir interprete**.
* En el apartado, **Base interpreter** ubicar la ruta del entorno ``tensorflow`` (entorno el cual se cre√≥ para la
instalaci√≥n de TF) y ubicar el archivo python. En nuestro caso la ruta es``C:\Users\user\anaconda3\envs\tensorflow\python.exe``
* Al seleccionar dicho int√©rprete, todas las dependencias instaladas dentro del entorno se cargar√°n y estar√°n disponibles
para su uso dentro del modelo. Adem√°s, puede verificar que el nombre del int√©rprete ha cambiado por el nombre del entorno 
(entre par√©ntesis) junto con la versi√≥n de python instalada espec√≠ficamente en este entorno.
![PyCharmInterprete1.png](Capturas/PyCharmInterprete2.png)

 ## Despliegue y construcci√≥n de API üì¶
Para mejorar la usabilidad del modelo, se consider√≥ la creaci√≥n de una API, la cual ser√° consumida por una interfaz 
gr√°fica, todo esto, con el fin de agilizar el proceso de evaluaci√≥n del modelo, y adem√°s mejorar la experiencia de uso por 
parte de los posibles usuarios finales (internos de medicina y radi√≥logos expertos que deseen cotejar sus diagn√≥sticos).

La API Rest en cuesti√≥n, fue creada usando [FastApi](https://fastapi.tiangolo.com/), 
la cual, mediante un m√©todo GET, recibe la direcci√≥n de la imagen que ser√° cargada de forma local mediante la interfaz
y luego subida a un repositorio de im√°genes llamado cloudinary. Este m√©todo por tanto permitir√° subir una imagene y a la 
vez obtener toda la informaci√≥n referente a esa imagen mediante una petici√≥n de consulta, la cual a su vez, har√° uso de
una funci√≥n que haga uso del modelo y este a su vez retorna como respuesta el valor de la predicci√≥n, tal como se 
muestra en la figura adjunta.
![DiagramasTT](Capturas/DiagramasTT.png)
Todo el esquema anterior se ha desplegado usando como base un proceso similar al utilizado en la fase de entrenamiento y
validaci√≥n del modelo, es decir, como primer, paso tenemos la entrada de datos, con la diferencia que ente caso se 
realizar√° una entrada a la vez. Seguidamente se realizar√° la transformaci√≥n de la imagen entrante a tensores, los cuales 
ser√°n evaluados por el modelo resultante. Por √∫ltimo, se cargar√° tanto el modelo como sus respectivos pesos, para 
realizar la clasificaci√≥n (diagn√≥stico) de la imagen entrante. El resultado de la predicci√≥n ser√° enviado como respuesta 
de la petici√≥n realizada con el m√©todo post del API.
El despliegue de la API, y su integraci√≥n en la UI, ha sido basada en la documentaci√≥n oficial de [FastApi](https://fastapi.tiangolo.com/es/deployment/deta/) 
Para levantar el servicio se utiliz√≥:
```buildoutcfg
uvicorn main:app --reload
```
Luego de haber desplegado la API usamos la siguiente direcci√≥n por defecto ``http://127.0.0.1:8000`` para acceder a la
UI de fastApi y poder comprobar la funcionalidad de la petici√≥n. Para ello accedemos a ``http://127.0.0.1:8000/docs``, 
con lo cual se despliega la siguiente IU:
![FastAPI_docs.PNG](Capturas/FastAPI_docs.PNG)
El m√©todo debemos comprobar ser√° el m√©todo POST ``/image/addres_img Load Image``, el cual solicita como par√°metro la ruta
de la radiograf√≠a a diagnosticar. Para ingresar dicho par√°metro y comprobar la respuesta que el modelo arroja accedemos 
al m√©todo y seleccionamos la opci√≥n ```Try it
out```, tal como se muestra a continuaci√≥n:
![FastAPI_tryItOut.PNG](Capturas/FastAPI_TryItOut.PNG)
Como atributo de ```ruta``` que el m√©todo post solicita debe utilizar la ruta de imagen, en nuestro caso, la ruta ser√°
la URL de la imagen que se encuentra alojada en el servicio de Cloudinary, v√©ase [Diagnos19](https://github.com/jr-98/Diagnos16),
donde se presenta el desarrollo de la UI y se explica el servicio de Cloudinary. 
No obstante, a continuaci√≥n, se presenta el resultado de la API al diagnosticar una radiograf√≠a, tal como se muestra en
las figuras adjuntas, el m√©todo devuelve un valor (0=Covid y 1= Normal), dicho sea de paso, la ruta enviada para la 
verificaci√≥n del m√©todo se trata de una imagen con ```normal```, por lo que el valor de respuesta de la 
API es ``{"valor":1}``.

![FastAPI_r1.PNG](Capturas/FastAPI_R1.PNG)
![FastAPI_r2.PNG](Capturas/FastAPI_R2.PNG)
Ademas, estos valores se contratan con los resultados arrojados por el modelo en la consola de PyCharm (IDE utilizado), 
la cual se presenta en la imagen adjunta:
![FastAPI_Console](Capturas/FastAPI_Console.PNG)
## Construido con üõ†Ô∏è
* [Python](https://www.python.org/) - Lenguaje de programaci√≥n de alto nivel, utilizado para el desarrollo de modelo de 
IA debido a la gran cantidad de librer√≠as, documentaci√≥n y soporte.  
* [TensorFlow](https://www.tensorflow.org/) - Librer√≠a Open Source, utilizada para el desarrollo y entrenamiento de 
modelos de ML. 
* [Django](https://www.djangoproject.com/) - Framework Open Source basado en Python, para la construcci√≥n r√°pida y eficiente de 
aplicaciones y servicios web.  
* [FastApi](https://fastapi.tiangolo.com/) - Usado para generar generar y desplegar la API que permite la utilizaci√≥n 
del modelo
* [Github](https://github.com/)- Repositorio usado para el alojar el c√≥digo y material concerniente al presente TT.

‚å® [jr-98](https://github.com/jr-98)